{"ast":null,"code":"// Set up audio context\nwindow.AudioContext = window.AudioContext || window.webkitAudioContext;\nconst audioContext = new AudioContext();\n/**\n * Retrieves audio from an external source, the initializes the drawing function\n * @param {String} url the url of the audio we'd like to fetch\n */\n\nfetch(url).then(response => response.arrayBuffer()).then(arrayBuffer => audioContext.decodeAudioData(arrayBuffer)).then(audioBuffer => {\n  return normalizeData(filterData(audioBuffer));\n});\n/**\n * Filters the AudioBuffer retrieved from an external source\n * @param {AudioBuffer} audioBuffer the AudioBuffer from drawAudio()\n * @returns {Array} an array of floating point numbers\n */\n\nconst filterData = audioBuffer => {\n  const rawData = audioBuffer.getChannelData(0); // We only need to work with one channel of data\n\n  const samples = 170; // Number of samples we want to have in our final data set\n\n  const blockSize = Math.floor(rawData.length / samples); // the number of samples in each subdivision\n\n  const filteredData = [];\n\n  for (let i = 0; i < samples; i++) {\n    let blockStart = blockSize * i; // the location of the first sample in the block\n\n    let sum = 0;\n\n    for (let j = 0; j < blockSize; j++) {\n      sum = sum + Math.abs(rawData[blockStart + j]); // find the sum of all the samples in the block\n    }\n\n    filteredData.push(sum / blockSize); // divide the sum by the block size to get the average\n  }\n\n  return filteredData;\n};\n/**\n * Normalizes the audio data to make a cleaner illustration \n * @param {Array} filteredData the data from filterData()\n * @returns {Array} an normalized array of floating point numbers\n */\n\n\nconst normalizeData = filteredData => {\n  const multiplier = Math.pow(Math.max(...filteredData), -1);\n  return filteredData.map(n => n * multiplier);\n};\n/**\n * Draws the audio file into a canvas element.\n * @param {Array} normalizedData The filtered array returned from filterData()\n * @returns {Array} a normalized array of data\n */\n\n\nconst draw = normalizedData => {\n  // set up the canvas\n  const canvas = document.querySelector(\"canvas\");\n  const dpr = window.devicePixelRatio || 1;\n  const padding = 20;\n  canvas.width = canvas.offsetWidth * dpr;\n  canvas.height = (canvas.offsetHeight + padding * 2) * dpr;\n  const ctx = canvas.getContext(\"2d\");\n  ctx.scale(dpr, dpr);\n  ctx.translate(0, canvas.offsetHeight / 2 + padding); // set Y = 0 to be in the middle of the canvas\n  // draw the line segments\n\n  const width = canvas.offsetWidth / normalizedData.length;\n\n  for (let i = 0; i < normalizedData.length; i++) {\n    const x = width * i;\n    let height = normalizedData[i] * canvas.offsetHeight - padding;\n\n    if (height < 0) {\n      height = 0;\n    } else if (height > canvas.offsetHeight / 2) {\n      height = height > canvas.offsetHeight / 2;\n    }\n\n    drawLineSegment(ctx, x, height, width, (i + 1) % 2);\n    console.log(normalizedData);\n  }\n};\n/**\n * A utility function for drawing our line segments\n * @param {AudioContext} ctx the audio context \n * @param {number} x  the x coordinate of the beginning of the line segment\n * @param {number} height the desired height of the line segment\n * @param {number} width the desired width of the line segment\n * @param {boolean} isEven whether or not the segmented is even-numbered\n */\n\n\nconst drawLineSegment = (ctx, x, height, width, isEven) => {\n  ctx.lineWidth = 1; // how thick the line is\n\n  ctx.strokeStyle = \"#fff\"; // what color our line is\n\n  ctx.beginPath();\n  height = isEven ? height : -height;\n  ctx.moveTo(x, 0);\n  ctx.lineTo(x, height);\n  ctx.arc(x + width / 2, height, width / 2, Math.PI, 0, isEven);\n  ctx.lineTo(x + width, 0);\n  ctx.stroke();\n};\n\nexport default fetch;","map":{"version":3,"sources":["/home/jan/sound-track-box/src/components/AudioAnalyzer.js"],"names":["window","AudioContext","webkitAudioContext","audioContext","fetch","url","then","response","arrayBuffer","decodeAudioData","audioBuffer","normalizeData","filterData","rawData","getChannelData","samples","blockSize","Math","floor","length","filteredData","i","blockStart","sum","j","abs","push","multiplier","pow","max","map","n","draw","normalizedData","canvas","document","querySelector","dpr","devicePixelRatio","padding","width","offsetWidth","height","offsetHeight","ctx","getContext","scale","translate","x","drawLineSegment","console","log","isEven","lineWidth","strokeStyle","beginPath","moveTo","lineTo","arc","PI","stroke"],"mappings":"AAAA;AACAA,MAAM,CAACC,YAAP,GAAsBD,MAAM,CAACC,YAAP,IAAuBD,MAAM,CAACE,kBAApD;AACA,MAAMC,YAAY,GAAG,IAAIF,YAAJ,EAArB;AAEA;AACA;AACA;AACA;;AACAG,KAAK,CAACC,GAAD,CAAL,CACKC,IADL,CACUC,QAAQ,IAAIA,QAAQ,CAACC,WAAT,EADtB,EAEKF,IAFL,CAEUE,WAAW,IAAIL,YAAY,CAACM,eAAb,CAA6BD,WAA7B,CAFzB,EAGKF,IAHL,CAGUI,WAAW,IAAI;AACjB,SAAOC,aAAa,CAACC,UAAU,CAACF,WAAD,CAAX,CAApB;AACH,CALL;AAOA;AACA;AACA;AACA;AACA;;AACA,MAAME,UAAU,GAAGF,WAAW,IAAI;AAC9B,QAAMG,OAAO,GAAGH,WAAW,CAACI,cAAZ,CAA2B,CAA3B,CAAhB,CAD8B,CACiB;;AAC/C,QAAMC,OAAO,GAAG,GAAhB,CAF8B,CAET;;AACrB,QAAMC,SAAS,GAAGC,IAAI,CAACC,KAAL,CAAWL,OAAO,CAACM,MAAR,GAAiBJ,OAA5B,CAAlB,CAH8B,CAG0B;;AACxD,QAAMK,YAAY,GAAG,EAArB;;AACA,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGN,OAApB,EAA6BM,CAAC,EAA9B,EAAkC;AAC9B,QAAIC,UAAU,GAAGN,SAAS,GAAGK,CAA7B,CAD8B,CACE;;AAChC,QAAIE,GAAG,GAAG,CAAV;;AACA,SAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGR,SAApB,EAA+BQ,CAAC,EAAhC,EAAoC;AAChCD,MAAAA,GAAG,GAAGA,GAAG,GAAGN,IAAI,CAACQ,GAAL,CAASZ,OAAO,CAACS,UAAU,GAAGE,CAAd,CAAhB,CAAZ,CADgC,CACe;AAClD;;AACDJ,IAAAA,YAAY,CAACM,IAAb,CAAkBH,GAAG,GAAGP,SAAxB,EAN8B,CAMM;AACvC;;AACD,SAAOI,YAAP;AACH,CAdD;AAgBA;AACA;AACA;AACA;AACA;;;AACA,MAAMT,aAAa,GAAGS,YAAY,IAAI;AAClC,QAAMO,UAAU,GAAGV,IAAI,CAACW,GAAL,CAASX,IAAI,CAACY,GAAL,CAAS,GAAGT,YAAZ,CAAT,EAAoC,CAAC,CAArC,CAAnB;AACA,SAAOA,YAAY,CAACU,GAAb,CAAiBC,CAAC,IAAIA,CAAC,GAAGJ,UAA1B,CAAP;AACH,CAHD;AAKA;AACA;AACA;AACA;AACA;;;AACA,MAAMK,IAAI,GAAGC,cAAc,IAAI;AAC3B;AACA,QAAMC,MAAM,GAAGC,QAAQ,CAACC,aAAT,CAAuB,QAAvB,CAAf;AACA,QAAMC,GAAG,GAAGrC,MAAM,CAACsC,gBAAP,IAA2B,CAAvC;AACA,QAAMC,OAAO,GAAG,EAAhB;AACAL,EAAAA,MAAM,CAACM,KAAP,GAAeN,MAAM,CAACO,WAAP,GAAqBJ,GAApC;AACAH,EAAAA,MAAM,CAACQ,MAAP,GAAgB,CAACR,MAAM,CAACS,YAAP,GAAsBJ,OAAO,GAAG,CAAjC,IAAsCF,GAAtD;AACA,QAAMO,GAAG,GAAGV,MAAM,CAACW,UAAP,CAAkB,IAAlB,CAAZ;AACAD,EAAAA,GAAG,CAACE,KAAJ,CAAUT,GAAV,EAAeA,GAAf;AACAO,EAAAA,GAAG,CAACG,SAAJ,CAAc,CAAd,EAAiBb,MAAM,CAACS,YAAP,GAAsB,CAAtB,GAA0BJ,OAA3C,EAT2B,CAS0B;AAErD;;AACA,QAAMC,KAAK,GAAGN,MAAM,CAACO,WAAP,GAAqBR,cAAc,CAACd,MAAlD;;AACA,OAAK,IAAIE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGY,cAAc,CAACd,MAAnC,EAA2CE,CAAC,EAA5C,EAAgD;AAC5C,UAAM2B,CAAC,GAAGR,KAAK,GAAGnB,CAAlB;AACA,QAAIqB,MAAM,GAAGT,cAAc,CAACZ,CAAD,CAAd,GAAoBa,MAAM,CAACS,YAA3B,GAA0CJ,OAAvD;;AACA,QAAIG,MAAM,GAAG,CAAb,EAAgB;AACZA,MAAAA,MAAM,GAAG,CAAT;AACH,KAFD,MAEO,IAAIA,MAAM,GAAGR,MAAM,CAACS,YAAP,GAAsB,CAAnC,EAAsC;AACzCD,MAAAA,MAAM,GAAGA,MAAM,GAAGR,MAAM,CAACS,YAAP,GAAsB,CAAxC;AACH;;AACDM,IAAAA,eAAe,CAACL,GAAD,EAAMI,CAAN,EAASN,MAAT,EAAiBF,KAAjB,EAAwB,CAACnB,CAAC,GAAG,CAAL,IAAU,CAAlC,CAAf;AACA6B,IAAAA,OAAO,CAACC,GAAR,CAAYlB,cAAZ;AACH;AACJ,CAxBD;AA0BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMgB,eAAe,GAAG,CAACL,GAAD,EAAMI,CAAN,EAASN,MAAT,EAAiBF,KAAjB,EAAwBY,MAAxB,KAAmC;AACvDR,EAAAA,GAAG,CAACS,SAAJ,GAAgB,CAAhB,CADuD,CACpC;;AACnBT,EAAAA,GAAG,CAACU,WAAJ,GAAkB,MAAlB,CAFuD,CAE7B;;AAC1BV,EAAAA,GAAG,CAACW,SAAJ;AACAb,EAAAA,MAAM,GAAGU,MAAM,GAAGV,MAAH,GAAY,CAACA,MAA5B;AACAE,EAAAA,GAAG,CAACY,MAAJ,CAAWR,CAAX,EAAc,CAAd;AACAJ,EAAAA,GAAG,CAACa,MAAJ,CAAWT,CAAX,EAAcN,MAAd;AACAE,EAAAA,GAAG,CAACc,GAAJ,CAAQV,CAAC,GAAGR,KAAK,GAAG,CAApB,EAAuBE,MAAvB,EAA+BF,KAAK,GAAG,CAAvC,EAA0CvB,IAAI,CAAC0C,EAA/C,EAAmD,CAAnD,EAAsDP,MAAtD;AACAR,EAAAA,GAAG,CAACa,MAAJ,CAAWT,CAAC,GAAGR,KAAf,EAAsB,CAAtB;AACAI,EAAAA,GAAG,CAACgB,MAAJ;AACH,CAVD;;AAYA,eAAexD,KAAf","sourcesContent":["// Set up audio context\nwindow.AudioContext = window.AudioContext || window.webkitAudioContext;\nconst audioContext = new AudioContext();\n\n/**\n * Retrieves audio from an external source, the initializes the drawing function\n * @param {String} url the url of the audio we'd like to fetch\n */\nfetch(url)\n    .then(response => response.arrayBuffer())\n    .then(arrayBuffer => audioContext.decodeAudioData(arrayBuffer))\n    .then(audioBuffer => {\n        return normalizeData(filterData(audioBuffer));\n    });\n\n/**\n * Filters the AudioBuffer retrieved from an external source\n * @param {AudioBuffer} audioBuffer the AudioBuffer from drawAudio()\n * @returns {Array} an array of floating point numbers\n */\nconst filterData = audioBuffer => {\n    const rawData = audioBuffer.getChannelData(0); // We only need to work with one channel of data\n    const samples = 170; // Number of samples we want to have in our final data set\n    const blockSize = Math.floor(rawData.length / samples); // the number of samples in each subdivision\n    const filteredData = [];\n    for (let i = 0; i < samples; i++) {\n        let blockStart = blockSize * i; // the location of the first sample in the block\n        let sum = 0;\n        for (let j = 0; j < blockSize; j++) {\n            sum = sum + Math.abs(rawData[blockStart + j]); // find the sum of all the samples in the block\n        }\n        filteredData.push(sum / blockSize); // divide the sum by the block size to get the average\n    }\n    return filteredData;\n};\n\n/**\n * Normalizes the audio data to make a cleaner illustration \n * @param {Array} filteredData the data from filterData()\n * @returns {Array} an normalized array of floating point numbers\n */\nconst normalizeData = filteredData => {\n    const multiplier = Math.pow(Math.max(...filteredData), -1);\n    return filteredData.map(n => n * multiplier);\n}\n\n/**\n * Draws the audio file into a canvas element.\n * @param {Array} normalizedData The filtered array returned from filterData()\n * @returns {Array} a normalized array of data\n */\nconst draw = normalizedData => {\n    // set up the canvas\n    const canvas = document.querySelector(\"canvas\");\n    const dpr = window.devicePixelRatio || 1;\n    const padding = 20;\n    canvas.width = canvas.offsetWidth * dpr;\n    canvas.height = (canvas.offsetHeight + padding * 2) * dpr;\n    const ctx = canvas.getContext(\"2d\");\n    ctx.scale(dpr, dpr);\n    ctx.translate(0, canvas.offsetHeight / 2 + padding); // set Y = 0 to be in the middle of the canvas\n\n    // draw the line segments\n    const width = canvas.offsetWidth / normalizedData.length;\n    for (let i = 0; i < normalizedData.length; i++) {\n        const x = width * i;\n        let height = normalizedData[i] * canvas.offsetHeight - padding;\n        if (height < 0) {\n            height = 0;\n        } else if (height > canvas.offsetHeight / 2) {\n            height = height > canvas.offsetHeight / 2;\n        }\n        drawLineSegment(ctx, x, height, width, (i + 1) % 2);\n        console.log(normalizedData);\n    }\n};\n\n/**\n * A utility function for drawing our line segments\n * @param {AudioContext} ctx the audio context \n * @param {number} x  the x coordinate of the beginning of the line segment\n * @param {number} height the desired height of the line segment\n * @param {number} width the desired width of the line segment\n * @param {boolean} isEven whether or not the segmented is even-numbered\n */\nconst drawLineSegment = (ctx, x, height, width, isEven) => {\n    ctx.lineWidth = 1; // how thick the line is\n    ctx.strokeStyle = \"#fff\"; // what color our line is\n    ctx.beginPath();\n    height = isEven ? height : -height;\n    ctx.moveTo(x, 0);\n    ctx.lineTo(x, height);\n    ctx.arc(x + width / 2, height, width / 2, Math.PI, 0, isEven);\n    ctx.lineTo(x + width, 0);\n    ctx.stroke();\n};\n\nexport default fetch;"]},"metadata":{},"sourceType":"module"}